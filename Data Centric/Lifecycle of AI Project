실무에서 AI프로젝트 생애주기
Software 2.0 : 인공지능(AI) 및 머신러닝(ML)을 활용해 기존의 소프트웨어 개발 방식과는 다른 접근법으로 문제를 해결하는 패러다임
SW2.0으로 인한 패러다임으로 데이터셋 제작의 중요성이 대두 되었고, 생애주기에도 데이터셋 제작의 중요성이 강조되었다.
실제 상품화되는 모델의 성능을 개선하고 유지보수하는데 좋은 데이터를 확보하는 것은 매우 중요하다.

AI Research vs AI Production
AI Research
정해진 데이터셋과 평가 방식으로 더 좋은 모델을 찾음

AI Production
데이터셋은 준비되어 있지 않고 서비스 요구사항만 존재함, 따라서 서비스에 적용되는 AI 개발 업무의 상당 부분이 데이터셋을 준비하는 작업임

-> 이때 서비스를 위한 요구사항을 충족시키는 모델을 지속적으로 확보하는 것이 중요한다
-> 이 방법은 데이터를 통해 모델 성능을 끌어올리는 방법과 모델 성능을 끌어올리는 방식이 있다.

서비스화를 위한 모델 성능 달성 시 데이터와 모델의 비중
데이터 : 모델 = 50:50
("QPS"는 Queries Per Second의 약자로, 시스템이나 서비스가 초당 처리할 수 있는 요청(query)의 수를 나타내는 성능 지표)

서비스 이후 모델 성능 개선 시 데이터와 모델에 대한 비중
데이터 : 모델 = 80 : 20
-> 서비스 출시 후에는 정확도에 대한 성능 개선 요구가 제일 많다.
-> 이때 정확도 개선을 위해 모델 구조를 변경하는 것은 처리 속도, qps, 메모리 크기 등에 대한 요구사항에 검증도 다시 해야 하므로 비용이 크다.

학계에서 데이터를 다루기 힘든 이유
1. 좋은 데이터를 많이 모으기 힘들다.
2. 라벨링 비용이 크다.
3. 작업 기간이 오래 걸린다.
뿐만 아니라, 데이터가 많다고 모델 성능이 항상 올라가는 것은 아니다. 따라서 제대로된 라벨링이 중요하다. 

라벨링 노이즈와 데이터 분포와 연관성
Common : 자주 보는 샘플은 라벨링 작업자도 인지하고 있고, 작업 가이드를 만들 때 해당 데이터를 고려해서 만들기 때문에 라벨링 노이즈가 적다.
Rare : 희귀 케이스인 경우 작업 가이드에서 다루지 않을 수도 있고, 라벨링 작업자별로 다르게 생각해 작업할 가능성이 크다.
=> Rare 케이스일 경우 해당 샘플들을 모아 라벨링 가이드를 만들어야 된다.

Data Engine & Flywheel
=> 데이터 관점에서 서비스 개발시 필요한 기능

데이터셋 시각화
-> 데이터, 레이블 분포 시각화, 레이블 시각화, 데이터 별 예측값 시각화

데이터 라벨링
-> 태스크 특화 기능, 라벨링 일관성 확인, 라벨링 작업 효율 확인, 자동 라벨링,...

데이터셋 정제
-> 반복 데이터 제거, 라벨링 오류 수정

데이터셋 선별
-> 모델 성능 향상을 위해 어떤 데이터를 라벨링 해야하는가?

[출처] https://velog.io/@hipjaengyi_cat18/Data-Centric-Lifecycle-of-AI-Project
